{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "import natsort\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MangaDataset(Dataset):\n",
    "    def __init__(self, main_dir, transform):\n",
    "        \n",
    "        self.bw_dir = os.path.join(main_dir, 'bw')\n",
    "        self.color_dir = os.path.join(main_dir, 'colored')\n",
    "        \n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "        colored_imgs = os.listdir(self.color_dir)\n",
    "        bw_imgs = os.listdir(self.bw_dir)\n",
    "        \n",
    "        self.total_colored_imgs = natsort.natsorted(colored_imgs)\n",
    "        self.total_bw_imgs = natsort.natsorted(bw_imgs)\n",
    "        \n",
    "        assert len(self.total_colored_imgs) == len(self.total_bw_imgs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.total_colored_imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        seed = np.random.randint(2147483647) # make a seed with numpy generator \n",
    "                \n",
    "        target_img = os.path.join(self.color_dir, self.total_colored_imgs[idx])\n",
    "        input_img = os.path.join(self.bw_dir, self.total_bw_imgs[idx])\n",
    "        \n",
    "        target = Image.open(target_img).convert(\"RGB\").resize((1024,1024))\n",
    "        \n",
    "        random.seed(seed) # apply this seed to img tranfsorms\n",
    "        torch.manual_seed(seed) # needed for torchvision 0.7\n",
    "        tensor_target = self.transform(target)\n",
    "        \n",
    "        \n",
    "        # ATTENTION: we can either use target_img or input_img\n",
    "        # target_img will generate BW input from colored image\n",
    "        # input_img will use actual original manga data\n",
    "        ipt = Image.open(target_img).convert(\"L\").resize((1024,1024))\n",
    "        \n",
    "        random.seed(seed) # apply this seed to target tranfsorms\n",
    "        torch.manual_seed(seed) # needed for torchvision 0.7\n",
    "        tensor_input = self.transform(ipt)\n",
    "        \n",
    "                \n",
    "        return tensor_input, tensor_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "        #                     std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "manga_dataset = MangaDataset('./dataset/one_piece', transform=data_transform)\n",
    "\n",
    "dataset_loader = torch.utils.data.DataLoader(manga_dataset,\n",
    "                                             batch_size=4, shuffle=True,\n",
    "                                             num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ColorizationNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipt, target = next(iter(dataset_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 224, 224])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(ipt)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
